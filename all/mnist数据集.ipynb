{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MNIST数据集相关常数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_NODE = 784 #输入层的节点数。对于MNIST数据集，这个就等于图片的像素。\n",
    "OUTPUT_NODE = 10 #输出层的节点数。这个等于类别的数目。因为在MNIST数据集中需要区分的事0-9，所以这里输出层的节点数为10。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 配置神经网络的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LAYER1_NODE = 500 #只有一个带有500个节点的隐藏层\n",
    "BATCH_SIZE = 100  #定义batch的大小\n",
    "LEARNING_RATE_BASE = 0.8  #基础的学习率\n",
    "LEARNING_RATE_DECAY = 0.99  \n",
    "#学习率的衰减率\n",
    "REGULARIZATION_RATE = 0.0001 #描述模型复杂度的正则化项在损失函数中的系数\n",
    "TRAINING_STEPS = 30000   #训练轮数\n",
    "MOVING_AVERAGE_DECAY = 0.99  #滑动平均距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(input_tensor,avg_class,weights1,biases1,weights2,biases2):\n",
    "    #当没有提供滑动平均类时，直接使用参数当前的取值\n",
    "    #这里实际含义是： avg_class == None 时，是训练时的前向传播过程，else时是为了在测试时计算准确里用的\n",
    "    if avg_class == None:\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor,weights1)+biases1)\n",
    "        return tf.matmul(layer1,weights2)+biases2\n",
    "    else:\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor,avg_class.average(weights1))+avg_class.average(biases1))\n",
    "        return tf.matmul(layer1,avg_class.average(weights2))+avg_class.average(biases2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(mnist):\n",
    "    x = tf.placeholder(tf.float32,[None,INPUT_NODE],name='x-input')\n",
    "    y_ = tf.placeholder(tf.float32,[None,OUTPUT_NODE],name='y-input')\n",
    "    #truncated_normal生成正太分布值\n",
    "    #隐藏层参数\n",
    "    weights1 = tf.Variable(tf.truncated_normal([INPUT_NODE,LAYER1_NODE],stddev=0.1))\n",
    "    biases1 = tf.Variable(tf.constant(0.1,shape=[LAYER1_NODE]))\n",
    "    #输出层参数\n",
    "    weights2 = tf.Variable(tf.truncated_normal([LAYER1_NODE,OUTPUT_NODE],stddev=0.1))\n",
    "    biases2 = tf.Variable(tf.constant(0.1,shape=[OUTPUT_NODE]))\n",
    "    \n",
    "    #计算未使用滑动平均一次前向传播结果\n",
    "    y = inference(x,None,weights1,biases1,weights2,biases2)\n",
    "    #定义当前步数，移动平均时会用到，自动更新+1\n",
    "    global_step = tf.Variable(0,trainable = False)\n",
    "    #计算使用滑动平均的前向传播结果\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY,global_step)\n",
    "    variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "    average_y = inference(x,variable_averages,weights1,biases1,weights2,biases2)\n",
    "    #在前向传播过后计算交叉熵\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y,labels=tf.argmax(y_,1))\n",
    "    #交叉熵平均值\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "    #正则项\n",
    "    regularizer=tf.contrib.layers.l2_regularizer(REGULARIZATION_RATE)\n",
    "    regularization = regularizer(weights1)+regularizer(weights2)\n",
    "    #损失等于交叉商加上正则项\n",
    "    loss = cross_entropy_mean + regularization\n",
    "    #定义学习率\n",
    "    learning_rate = tf.train.exponential_decay(LEARNING_RATE_BASE,#基础学习速率\n",
    "                                              global_step,       #当前迭代轮数\n",
    "                                              mnist.train.num_examples/BATCH_SIZE,  #总共需要的迭代次数\n",
    "                                              LEARNING_RATE_DECAY)      #学习率衰减速率\n",
    "    #训练过程\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate)\\\n",
    "                    .minimize(loss,global_step = global_step)\n",
    "    #反向传播和滑动平均更新参数，这里直接实现了前向及逆向传播过程，在利用滑动平均更新参数的一整个过程\n",
    "    #with tf.control_dependencies([train_step,variables_averages_op]):\n",
    "        #train_op = tf.no_op(name='train')\n",
    "    train_op = tf.group(train_step,variables_averages_op) \n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(average_y,1),tf.argmax(y_,1))\n",
    "    #计算出准确度，此处将bool转换成0，1，再用reduce_mean算1占的比例就可以得出准确度，可用一下注释代码验证\n",
    "    #tmp = tf.Variable([True,False,True])\n",
    "    #tmp1  = tf.cast(tmp,dtype=tf.float32)\n",
    "    #with tf.Session() as sess1:\n",
    "        #tf.global_variables_initializer().run()\n",
    "        #print(sess1.run(tf.reduce_mean(sess1.run(tmp1))))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    with tf.Session() as sess:\n",
    "        #验证数据\n",
    "        tf.global_variables_initializer().run()\n",
    "        validate_feed = {x:mnist.validation.images,y_:mnist.validation.labels}\n",
    "        #测试数据\n",
    "        test_feed = {x:mnist.test.images,y_:mnist.test.labels}\n",
    "    \n",
    "        for i in range(TRAINING_STEPS):\n",
    "            if i%1000 == 0:\n",
    "                validate_acc = sess.run(accuracy,feed_dict=validate_feed)\n",
    "                print(\"after %d training step(s),validation accuracy \" \"using average model is %g\" %(i,validate_acc))\n",
    "            xs,ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "            sess.run(train_op,feed_dict={x:xs,y_:ys})\n",
    "        test_acc = sess.run(accuracy,feed_dict=test_feed)\n",
    "        print(\"after %d training step(s),validation accuracy \" \"using average model is %g\" %(TRAINING_STEPS,test_acc))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /Users/zhouzelun/Documents/python/mnist_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /Users/zhouzelun/Documents/python/mnist_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /Users/zhouzelun/Documents/python/mnist_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /Users/zhouzelun/Documents/python/mnist_data/t10k-labels-idx1-ubyte.gz\n",
      "after 0 training step(s),validation accuracy using average model is 0.1614\n",
      "after 1000 training step(s),validation accuracy using average model is 0.977\n",
      "after 2000 training step(s),validation accuracy using average model is 0.9816\n",
      "after 3000 training step(s),validation accuracy using average model is 0.9824\n",
      "after 4000 training step(s),validation accuracy using average model is 0.9848\n",
      "after 5000 training step(s),validation accuracy using average model is 0.9836\n",
      "after 6000 training step(s),validation accuracy using average model is 0.9852\n",
      "after 7000 training step(s),validation accuracy using average model is 0.984\n",
      "after 8000 training step(s),validation accuracy using average model is 0.984\n",
      "after 9000 training step(s),validation accuracy using average model is 0.9836\n",
      "after 10000 training step(s),validation accuracy using average model is 0.984\n",
      "after 11000 training step(s),validation accuracy using average model is 0.9842\n",
      "after 12000 training step(s),validation accuracy using average model is 0.984\n",
      "after 13000 training step(s),validation accuracy using average model is 0.984\n",
      "after 14000 training step(s),validation accuracy using average model is 0.9846\n",
      "after 15000 training step(s),validation accuracy using average model is 0.9848\n",
      "after 16000 training step(s),validation accuracy using average model is 0.9848\n",
      "after 17000 training step(s),validation accuracy using average model is 0.9848\n",
      "after 18000 training step(s),validation accuracy using average model is 0.9846\n",
      "after 19000 training step(s),validation accuracy using average model is 0.9848\n",
      "after 20000 training step(s),validation accuracy using average model is 0.9854\n",
      "after 21000 training step(s),validation accuracy using average model is 0.9838\n",
      "after 22000 training step(s),validation accuracy using average model is 0.9846\n",
      "after 23000 training step(s),validation accuracy using average model is 0.9848\n",
      "after 24000 training step(s),validation accuracy using average model is 0.9848\n",
      "after 25000 training step(s),validation accuracy using average model is 0.9856\n",
      "after 26000 training step(s),validation accuracy using average model is 0.9848\n",
      "after 27000 training step(s),validation accuracy using average model is 0.9846\n",
      "after 28000 training step(s),validation accuracy using average model is 0.9852\n",
      "after 29000 training step(s),validation accuracy using average model is 0.985\n",
      "after 30000 training step(s),validation accuracy using average model is 0.984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/Users/zhouzelun/Documents/python/mnist_data\",one_hot=True)\n",
    "train(mnist)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
